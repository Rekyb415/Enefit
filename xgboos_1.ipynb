{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WT6pV_MvQT7-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import  matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import holidays\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wJ0L-ti70pJd"
   },
   "outputs": [],
   "source": [
    "# GPU or CPU use for model\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VhGl5h0vP6J_"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/My Drive/Enefit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "L28df69UQFAX"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "gas_df = pd.read_csv(\"gas_prices.csv\")\n",
    "electricity_df = pd.read_csv(\"electricity_prices.csv\")\n",
    "client_df = pd.read_csv(\"client.csv\")\n",
    "fw_df = pd.read_csv(\"forecast_weather.csv\")\n",
    "hw_df = pd.read_csv(\"historical_weather.csv\")\n",
    "location = pd.read_csv(\"county_lon_lats.csv\")\n",
    "location = location.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0v_NrtyvRX7s"
   },
   "outputs": [],
   "source": [
    "class FeatureProcessorClass():\n",
    "    def __init__(self):\n",
    "        # Columns to join on for the different datasets\n",
    "        self.weather_join = ['datetime', 'county', 'data_block_id']\n",
    "        self.gas_join = ['datetime','data_block_id']\n",
    "        self.electricity_join = ['datetime', 'data_block_id']\n",
    "        self.client_join = ['county', 'is_business', 'product_type', 'data_block_id']\n",
    "        self.holiday = ['datetime']\n",
    "        # Columns of latitude & longitude\n",
    "        self.lat_lon_columns = ['latitude', 'longitude']\n",
    "\n",
    "        # Aggregate stats\n",
    "        self.agg_stats = ['mean'] #, 'min', 'max', 'std', 'median']\n",
    "\n",
    "        # Categorical columns (specify for XGBoost)\n",
    "        self.category_columns = ['county', 'is_business', 'product_type', 'is_consumption', 'data_block_id','holiday']\n",
    "\n",
    "    def create_new_column_names(self, df, suffix, columns_no_change):\n",
    "        '''Change column names by given suffix, keep columns_no_change, and return back the data'''\n",
    "        df.columns = [col + suffix\n",
    "                      if col not in columns_no_change\n",
    "                      else col\n",
    "                      for col in df.columns\n",
    "                      ]\n",
    "        return df\n",
    "\n",
    "    def flatten_multi_index_columns(self, df):\n",
    "        df.columns = ['_'.join([col for col in multi_col if len(col)>0])\n",
    "                      for multi_col in df.columns]\n",
    "        return df\n",
    "\n",
    "    def create_data_features(self, data):\n",
    "        '''📊Create features for main data (test or train) set📊'''\n",
    "        # To datetime\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "        # Time period features\n",
    "        data['date'] = data['datetime'].dt.normalize()\n",
    "        data['year'] = data['datetime'].dt.year\n",
    "        data['quarter'] = data['datetime'].dt.quarter\n",
    "        data['month'] = data['datetime'].dt.month\n",
    "        data['week'] = data['datetime'].dt.isocalendar().week\n",
    "        data['hour'] = data['datetime'].dt.hour\n",
    "\n",
    "        # Day features\n",
    "        data['day_of_year'] = data['datetime'].dt.day_of_year\n",
    "        data['day_of_month']  = data['datetime'].dt.day\n",
    "        data['day_of_week'] = data['datetime'].dt.day_of_week\n",
    "        return data\n",
    "\n",
    "    def create_client_features(self, client):\n",
    "        '''💼 Create client features 💼'''\n",
    "        # Modify column names - specify suffix\n",
    "        client = self.create_new_column_names(client,\n",
    "                                           suffix='_client',\n",
    "                                           columns_no_change = self.client_join\n",
    "                                          )\n",
    "        client['data_block_id']-=2\n",
    "        return client\n",
    "\n",
    "    def create_historical_weather_features(self, historical_weather):\n",
    "        '''⌛🌤️ Create historical weather features 🌤️⌛'''\n",
    "\n",
    "        # To datetime\n",
    "        historical_weather['datetime'] = pd.to_datetime(historical_weather['datetime'])\n",
    "\n",
    "        # Add county\n",
    "        historical_weather[self.lat_lon_columns] = historical_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        historical_weather = historical_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        historical_weather = self.create_new_column_names(historical_weather,\n",
    "                                                          suffix='_h',\n",
    "                                                          columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                          )\n",
    "\n",
    "        # Group by & calculate aggregate stats\n",
    "        agg_columns = [col for col in historical_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        historical_weather = historical_weather.groupby(self.weather_join).agg(agg_dict).reset_index()\n",
    "        # Flatten the multi column aggregates\n",
    "        historical_weather = self.flatten_multi_index_columns(historical_weather)\n",
    "\n",
    "        # Test set has 1 day offset for hour<11 and 2 day offset for hour>11\n",
    "        # historical_weather['hour_h'] = historical_weather['datetime'].dt.hour\n",
    "        # historical_weather['datetime'] = (historical_weather\n",
    "        #                                        .apply(lambda x:\n",
    "        #                                               x['datetime'] + pd.DateOffset(1)\n",
    "        #                                               if x['hour_h']< 11\n",
    "        #                                               else x['datetime'] + pd.DateOffset(2),\n",
    "        #                                               axis=1)\n",
    "        #                                       )\n",
    "        historical_weather['data_block_id'] = historical_weather['data_block_id'].astype(int)\n",
    "        historical_weather['data_block_id'] -= 1\n",
    "\n",
    "        return historical_weather\n",
    "\n",
    "    def create_forecast_weather_features(self, forecast_weather):\n",
    "        '''🔮🌤️ Create forecast weather features 🌤️🔮'''\n",
    "\n",
    "        # Rename column and drop\n",
    "        forecast_weather = (forecast_weather\n",
    "                            .rename(columns = {'forecast_datetime': 'datetime'})\n",
    "                            .drop(columns = 'origin_datetime')\n",
    "                           )\n",
    "\n",
    "        # To datetime\n",
    "        forecast_weather['datetime'] = (pd.to_datetime(forecast_weather['datetime'])\n",
    "                                        .dt\n",
    "                                        .tz_localize(None)\n",
    "                                       )\n",
    "\n",
    "        # Add county\n",
    "        forecast_weather[self.lat_lon_columns] = forecast_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        forecast_weather = forecast_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        forecast_weather = self.create_new_column_names(forecast_weather,\n",
    "                                                        suffix='_f',\n",
    "                                                        columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                        )\n",
    "\n",
    "        # Group by & calculate aggregate stats\n",
    "        agg_columns = [col for col in forecast_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        forecast_weather = forecast_weather.groupby(self.weather_join).agg(agg_dict).reset_index()\n",
    "\n",
    "        # Flatten the multi column aggregates\n",
    "        forecast_weather = self.flatten_multi_index_columns(forecast_weather)\n",
    "        forecast_weather['data_block_id'] -= 1\n",
    "        return forecast_weather\n",
    "\n",
    "    def create_electricity_features(self, electricity):\n",
    "        '''⚡ Create electricity prices features ⚡'''\n",
    "        # To datetime\n",
    "        electricity['forecast_date'] = pd.to_datetime(electricity['forecast_date'])\n",
    "\n",
    "        # Test set has 1 day offset\n",
    "        electricity['datetime'] = electricity['forecast_date']\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        electricity = self.create_new_column_names(electricity,\n",
    "                                                   suffix='_electricity',\n",
    "                                                   columns_no_change = self.electricity_join)\n",
    "        electricity['data_block_id']-=1\n",
    "        return electricity\n",
    "\n",
    "    def create_gas_features(self, gas):\n",
    "        '''⛽ Create gas prices features ⛽'''\n",
    "        gas['forecast_date'] = pd.to_datetime(gas['forecast_date'])\n",
    "        gas['datetime'] = gas['forecast_date']\n",
    "\n",
    "        # Mean gas price\n",
    "        gas['mean_price_per_mwh'] = (gas['lowest_price_per_mwh'] + gas['highest_price_per_mwh'])/2\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        gas = self.create_new_column_names(gas,\n",
    "                                           suffix='_gas',\n",
    "                                           columns_no_change = self.gas_join\n",
    "                                          )\n",
    "        gas['data_block_id']-=1\n",
    "\n",
    "        return gas\n",
    "\n",
    "    def get_holiday_features(self, df, country_code='US'):\n",
    "\n",
    "        year_range = list(range(min(df['datetime'].dt.year), max(df['datetime'].dt.year) + 1))\n",
    "        country_holidays = holidays.country_holidays(\n",
    "        country_code,\n",
    "        years=year_range,\n",
    "        observed=False\n",
    "        )\n",
    "        holiday = pd.DataFrame(country_holidays.items())\n",
    "        holiday.columns = ['date', 'holiday']\n",
    "        holiday['date'] = pd.to_datetime(holiday['date'])\n",
    "        holiday = holiday.rename(columns={'date': 'datetime'})\n",
    "        holiday['datetime'] = pd.to_datetime(holiday['datetime'])\n",
    "\n",
    "        return holiday\n",
    "    def __call__(self, data, client, historical_weather, forecast_weather, electricity, gas):\n",
    "        '''Processing of features from all datasets, merge together and return features for dataframe df '''\n",
    "        # Create features for relevant dataset\n",
    "        data = self.create_data_features(data)\n",
    "        client = self.create_client_features(client)\n",
    "        historical_weather = self.create_historical_weather_features(historical_weather)\n",
    "        forecast_weather = self.create_forecast_weather_features(forecast_weather)\n",
    "        electricity = self.create_electricity_features(electricity)\n",
    "        gas = self.create_gas_features(gas)\n",
    "        holiday = self.get_holiday_features(data)\n",
    "        # 🔗 Merge all datasets into one df 🔗\n",
    "        df = data.merge(client, how='left', on = self.client_join)\n",
    "        df = df.merge(historical_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(forecast_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(electricity, how='left', on = self.electricity_join)\n",
    "        df = df.merge(gas, how='left', on = self.gas_join)\n",
    "        df = df.merge(holiday, how='left', on = self.holiday)\n",
    "        # Assuming 'df' is your DataFrame containing the 'holiday' column\n",
    "        df['holiday'] = df['holiday'].fillna(0)  # Fill NaN values with 0\n",
    "        df.loc[df['holiday'] != 0, 'holiday'] = 1  # Change non-zero values to 1\n",
    "\n",
    "\n",
    "        # Change columns to categorical for XGBoost\n",
    "        df[self.category_columns] = df[self.category_columns].astype('category')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "y2Ow5_Fxyr69"
   },
   "outputs": [],
   "source": [
    "def create_revealed_targets_train(data, N_day_lags):\n",
    "    '''🎯 Create past revealed_targets for train set based on number of day lags N_day_lags 🎯 '''\n",
    "    original_datetime = data['datetime']\n",
    "    revealed_targets = data[['datetime', 'prediction_unit_id', 'is_consumption', 'target']].copy()\n",
    "\n",
    "    # Create revealed targets for all day lags\n",
    "    for day_lag in range(2, N_day_lags+1):\n",
    "        revealed_targets['datetime'] = original_datetime + pd.DateOffset(day_lag)\n",
    "        data = data.merge(revealed_targets,\n",
    "                          how='left',\n",
    "                          on = ['datetime', 'prediction_unit_id', 'is_consumption'],\n",
    "                          suffixes = ('', f'_{day_lag}_days_ago')\n",
    "                         )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJ9GYLkGdVPV",
    "outputId": "eca2126d-356e-47a1-c60b-3f377394b14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.26 s, sys: 3.72 s, total: 8.98 s\n",
      "Wall time: 9.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create all features\n",
    "\n",
    "FeatureProcessor = FeatureProcessorClass()\n",
    "\n",
    "data = FeatureProcessor(data = train_df.copy(),\n",
    "                      client = client_df.copy(),\n",
    "                      historical_weather = hw_df.copy(),\n",
    "                      forecast_weather = fw_df.copy(),\n",
    "                      electricity = electricity_df.copy(),\n",
    "                      gas = gas_df.copy(),\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "UpTXBW-TRMnU",
    "outputId": "2c4bb48d-245d-455a-efbd-affc953bf8b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>datetime</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>total_precipitation_f_mean</th>\n",
       "      <th>forecast_date_electricity</th>\n",
       "      <th>euros_per_mwh_electricity</th>\n",
       "      <th>origin_date_electricity</th>\n",
       "      <th>forecast_date_gas</th>\n",
       "      <th>lowest_price_per_mwh_gas</th>\n",
       "      <th>highest_price_per_mwh_gas</th>\n",
       "      <th>origin_date_gas</th>\n",
       "      <th>mean_price_per_mwh_gas</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>45.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.590</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>45.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>45.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.314</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>45.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.904</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>92.51</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>45.23</td>\n",
       "      <td>46.32</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>45.775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  county is_business product_type  target is_consumption   datetime  \\\n",
       "0      0           0            1   0.713              0 2021-09-01   \n",
       "1      0           0            1  96.590              1 2021-09-01   \n",
       "2      0           0            2   0.000              0 2021-09-01   \n",
       "3      0           0            2  17.314              1 2021-09-01   \n",
       "4      0           0            3   2.904              0 2021-09-01   \n",
       "\n",
       "  data_block_id  row_id  prediction_unit_id       date  ...  \\\n",
       "0             0       0                   0 2021-09-01  ...   \n",
       "1             0       1                   0 2021-09-01  ...   \n",
       "2             0       2                   1 2021-09-01  ...   \n",
       "3             0       3                   1 2021-09-01  ...   \n",
       "4             0       4                   2 2021-09-01  ...   \n",
       "\n",
       "   total_precipitation_f_mean  forecast_date_electricity  \\\n",
       "0                         NaN                 2021-09-01   \n",
       "1                         NaN                 2021-09-01   \n",
       "2                         NaN                 2021-09-01   \n",
       "3                         NaN                 2021-09-01   \n",
       "4                         NaN                 2021-09-01   \n",
       "\n",
       "   euros_per_mwh_electricity  origin_date_electricity  forecast_date_gas  \\\n",
       "0                      92.51      2021-08-31 00:00:00         2021-09-01   \n",
       "1                      92.51      2021-08-31 00:00:00         2021-09-01   \n",
       "2                      92.51      2021-08-31 00:00:00         2021-09-01   \n",
       "3                      92.51      2021-08-31 00:00:00         2021-09-01   \n",
       "4                      92.51      2021-08-31 00:00:00         2021-09-01   \n",
       "\n",
       "   lowest_price_per_mwh_gas  highest_price_per_mwh_gas  origin_date_gas  \\\n",
       "0                     45.23                      46.32       2021-08-31   \n",
       "1                     45.23                      46.32       2021-08-31   \n",
       "2                     45.23                      46.32       2021-08-31   \n",
       "3                     45.23                      46.32       2021-08-31   \n",
       "4                     45.23                      46.32       2021-08-31   \n",
       "\n",
       "   mean_price_per_mwh_gas  holiday  \n",
       "0                  45.775        0  \n",
       "1                  45.775        0  \n",
       "2                  45.775        0  \n",
       "3                  45.775        0  \n",
       "4                  45.775        0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KpaST7ZhPzYp"
   },
   "outputs": [],
   "source": [
    "N_day_lags = 7 # Specify how many days we want to go back (at least 2)\n",
    "\n",
    "df = create_revealed_targets_train(data.copy(),\n",
    "                                  N_day_lags = N_day_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_target_days'] = df[[f\"target_{i}_days_ago\" for i in range(2, 15)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ctqSCLwsy6JO"
   },
   "outputs": [],
   "source": [
    "# Remove empty target row\n",
    "target = 'target'\n",
    "df = df[df[target].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yX85MmxgyfNl"
   },
   "outputs": [],
   "source": [
    "#### Create single fold split ######\n",
    "train_block_id = list(range(0, 600))\n",
    "\n",
    "tr = df[df['data_block_id'].isin(train_block_id)] # first 600 data_block_ids used for training\n",
    "val = df[~df['data_block_id'].isin(train_block_id)] # rest data_block_ids used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgrGD944yhgE",
    "outputId": "11376aa6-2362-4eda-f900-6948543a14ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'data_block_id',\n",
       " 'row_id',\n",
       " 'date',\n",
       " 'date_client',\n",
       " 'hours_ahead_f_mean',\n",
       " 'forecast_date_electricity',\n",
       " 'origin_date_electricity',\n",
       " 'forecast_date_gas',\n",
       " 'origin_date_gas']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns for features\n",
    "no_features = ['date',\n",
    "                'latitude',\n",
    "                'longitude',\n",
    "                'data_block_id',\n",
    "                'row_id',\n",
    "                'hours_ahead',\n",
    "                'hour_h',\n",
    "               ]\n",
    "\n",
    "remove_columns = [col for col in df.columns for no_feature in no_features if no_feature in col]\n",
    "remove_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2up5YReKQtI1",
    "outputId": "7d6a2037-06c2-43de-8941-571891477b17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'data_block_id',\n",
       " 'row_id',\n",
       " 'date',\n",
       " 'date_client',\n",
       " 'hours_ahead_f_mean',\n",
       " 'forecast_date_electricity',\n",
       " 'origin_date_electricity',\n",
       " 'forecast_date_gas',\n",
       " 'origin_date_gas',\n",
       " 'target']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_columns.append(target)\n",
    "remove_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECBT2lPJQ5VX",
    "outputId": "51066250-28fa-49ee-d64a-17a134fdb9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['county',\n",
       " 'is_business',\n",
       " 'product_type',\n",
       " 'is_consumption',\n",
       " 'prediction_unit_id',\n",
       " 'year',\n",
       " 'quarter',\n",
       " 'month',\n",
       " 'week',\n",
       " 'hour',\n",
       " 'day_of_year',\n",
       " 'day_of_month',\n",
       " 'day_of_week',\n",
       " 'eic_count_client',\n",
       " 'installed_capacity_client',\n",
       " 'temperature_h_mean',\n",
       " 'dewpoint_h_mean',\n",
       " 'rain_h_mean',\n",
       " 'snowfall_h_mean',\n",
       " 'surface_pressure_h_mean',\n",
       " 'cloudcover_total_h_mean',\n",
       " 'cloudcover_low_h_mean',\n",
       " 'cloudcover_mid_h_mean',\n",
       " 'cloudcover_high_h_mean',\n",
       " 'windspeed_10m_h_mean',\n",
       " 'winddirection_10m_h_mean',\n",
       " 'shortwave_radiation_h_mean',\n",
       " 'direct_solar_radiation_h_mean',\n",
       " 'diffuse_radiation_h_mean',\n",
       " 'temperature_f_mean',\n",
       " 'dewpoint_f_mean',\n",
       " 'cloudcover_high_f_mean',\n",
       " 'cloudcover_low_f_mean',\n",
       " 'cloudcover_mid_f_mean',\n",
       " 'cloudcover_total_f_mean',\n",
       " '10_metre_u_wind_component_f_mean',\n",
       " '10_metre_v_wind_component_f_mean',\n",
       " 'direct_solar_radiation_f_mean',\n",
       " 'surface_solar_radiation_downwards_f_mean',\n",
       " 'snowfall_f_mean',\n",
       " 'total_precipitation_f_mean',\n",
       " 'euros_per_mwh_electricity',\n",
       " 'lowest_price_per_mwh_gas',\n",
       " 'highest_price_per_mwh_gas',\n",
       " 'mean_price_per_mwh_gas',\n",
       " 'holiday',\n",
       " 'target_2_days_ago',\n",
       " 'target_3_days_ago',\n",
       " 'target_4_days_ago',\n",
       " 'target_5_days_ago',\n",
       " 'target_6_days_ago',\n",
       " 'target_7_days_ago']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [col for col in df.columns if col not in remove_columns]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_-oPREwqykCC"
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor(\n",
    "                        device = device,\n",
    "                        booster='dart',\n",
    "                        enable_categorical=True,\n",
    "                        objective = 'reg:absoluteerror',\n",
    "                        n_estimators = 1000,\n",
    "                        early_stopping_rounds=100\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJJqDR3mymIz",
    "outputId": "7a8c65d2-82f1-41b0-eb65-493c5fe2b082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:241.45887\tvalidation_1-mae:313.88049\n",
      "[1]\tvalidation_0-mae:215.81322\tvalidation_1-mae:282.69834\n",
      "[2]\tvalidation_0-mae:190.54369\tvalidation_1-mae:251.50425\n",
      "[3]\tvalidation_0-mae:169.09840\tvalidation_1-mae:225.66084\n",
      "[4]\tvalidation_0-mae:152.37100\tvalidation_1-mae:203.15422\n",
      "[5]\tvalidation_0-mae:138.60647\tvalidation_1-mae:183.19125\n",
      "[6]\tvalidation_0-mae:127.65798\tvalidation_1-mae:169.82069\n",
      "[7]\tvalidation_0-mae:107.41947\tvalidation_1-mae:147.55239\n",
      "[8]\tvalidation_0-mae:91.04654\tvalidation_1-mae:128.89447\n",
      "[9]\tvalidation_0-mae:79.77534\tvalidation_1-mae:116.70160\n",
      "[10]\tvalidation_0-mae:72.33868\tvalidation_1-mae:108.92734\n",
      "[11]\tvalidation_0-mae:66.66078\tvalidation_1-mae:103.34935\n",
      "[12]\tvalidation_0-mae:62.48779\tvalidation_1-mae:100.46281\n",
      "[13]\tvalidation_0-mae:59.68738\tvalidation_1-mae:97.88880\n",
      "[14]\tvalidation_0-mae:58.08449\tvalidation_1-mae:96.81214\n",
      "[15]\tvalidation_0-mae:57.28157\tvalidation_1-mae:96.10353\n",
      "[16]\tvalidation_0-mae:56.27682\tvalidation_1-mae:95.80043\n",
      "[17]\tvalidation_0-mae:55.99301\tvalidation_1-mae:95.59102\n",
      "[18]\tvalidation_0-mae:55.64135\tvalidation_1-mae:95.38935\n",
      "[19]\tvalidation_0-mae:54.94992\tvalidation_1-mae:94.64902\n",
      "[20]\tvalidation_0-mae:54.71864\tvalidation_1-mae:94.56417\n",
      "[21]\tvalidation_0-mae:54.61566\tvalidation_1-mae:94.46978\n",
      "[22]\tvalidation_0-mae:54.56468\tvalidation_1-mae:94.44525\n",
      "[23]\tvalidation_0-mae:54.17932\tvalidation_1-mae:94.20852\n",
      "[24]\tvalidation_0-mae:54.06513\tvalidation_1-mae:94.09371\n",
      "[25]\tvalidation_0-mae:53.70724\tvalidation_1-mae:93.57684\n",
      "[26]\tvalidation_0-mae:53.65194\tvalidation_1-mae:93.54484\n",
      "[27]\tvalidation_0-mae:53.56637\tvalidation_1-mae:93.51890\n",
      "[28]\tvalidation_0-mae:53.21270\tvalidation_1-mae:92.24226\n",
      "[29]\tvalidation_0-mae:53.17676\tvalidation_1-mae:92.23440\n",
      "[30]\tvalidation_0-mae:53.15801\tvalidation_1-mae:92.22902\n",
      "[31]\tvalidation_0-mae:53.14237\tvalidation_1-mae:92.23219\n",
      "[32]\tvalidation_0-mae:52.99174\tvalidation_1-mae:91.98774\n",
      "[33]\tvalidation_0-mae:52.96846\tvalidation_1-mae:91.98135\n",
      "[34]\tvalidation_0-mae:52.89605\tvalidation_1-mae:91.88176\n",
      "[35]\tvalidation_0-mae:52.77758\tvalidation_1-mae:91.82112\n",
      "[36]\tvalidation_0-mae:52.26296\tvalidation_1-mae:91.07602\n",
      "[37]\tvalidation_0-mae:51.80054\tvalidation_1-mae:91.04797\n",
      "[38]\tvalidation_0-mae:51.73784\tvalidation_1-mae:90.97718\n",
      "[39]\tvalidation_0-mae:51.40249\tvalidation_1-mae:90.50268\n",
      "[40]\tvalidation_0-mae:51.35377\tvalidation_1-mae:90.50247\n",
      "[41]\tvalidation_0-mae:51.26987\tvalidation_1-mae:90.42843\n",
      "[42]\tvalidation_0-mae:51.21912\tvalidation_1-mae:90.46315\n",
      "[43]\tvalidation_0-mae:51.03935\tvalidation_1-mae:90.17034\n",
      "[44]\tvalidation_0-mae:50.97891\tvalidation_1-mae:90.19259\n",
      "[45]\tvalidation_0-mae:50.80804\tvalidation_1-mae:89.98417\n",
      "[46]\tvalidation_0-mae:50.54257\tvalidation_1-mae:89.76082\n",
      "[47]\tvalidation_0-mae:50.47979\tvalidation_1-mae:89.73775\n",
      "[48]\tvalidation_0-mae:50.11446\tvalidation_1-mae:89.44343\n",
      "[49]\tvalidation_0-mae:50.04138\tvalidation_1-mae:89.44189\n",
      "[50]\tvalidation_0-mae:49.70488\tvalidation_1-mae:88.90575\n",
      "[51]\tvalidation_0-mae:49.41426\tvalidation_1-mae:88.66046\n",
      "[52]\tvalidation_0-mae:49.23814\tvalidation_1-mae:88.43299\n",
      "[53]\tvalidation_0-mae:49.06106\tvalidation_1-mae:88.15482\n",
      "[54]\tvalidation_0-mae:48.88408\tvalidation_1-mae:88.05542\n",
      "[55]\tvalidation_0-mae:48.80733\tvalidation_1-mae:87.97765\n",
      "[56]\tvalidation_0-mae:48.14011\tvalidation_1-mae:87.46032\n",
      "[57]\tvalidation_0-mae:48.08961\tvalidation_1-mae:87.40464\n",
      "[58]\tvalidation_0-mae:48.01952\tvalidation_1-mae:87.30866\n",
      "[59]\tvalidation_0-mae:47.69087\tvalidation_1-mae:86.22475\n",
      "[60]\tvalidation_0-mae:47.66913\tvalidation_1-mae:86.21935\n",
      "[61]\tvalidation_0-mae:47.58341\tvalidation_1-mae:86.10551\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X = tr[features],\n",
    "        y = tr[target],\n",
    "        eval_set = [(tr[features], tr[target]), (val[features], val[target])],\n",
    "        verbose=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'n_estimators': 5000,\n",
    "    'verbosity': 0,  # 0 (silent), 1 (warning), 2 (info), 3 (debug)\n",
    "    'objective': 'reg:tweedie',\n",
    "    'num_leaves': 455,\n",
    "    'learning_rate': 0.0095,\n",
    "    'colsample_bytree': 0.92,\n",
    "    'subsample': 0.45,\n",
    "    'reg_alpha': 3.62,\n",
    "    'reg_lambda': 1.65,\n",
    "    'min_child_weight': 198,\n",
    "    'max_depth': 21,\n",
    "    'random_state': 73\n",
    "}\n",
    "\n",
    "clf_1 = XGBRegressor(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1.fit(X = tr[features],\n",
    "        y = tr[target],\n",
    "        eval_set = [(tr[features], tr[target]), (val[features], val[target])],\n",
    "        eval_metric='mae',\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLQ880aLKKk8"
   },
   "outputs": [],
   "source": [
    "# Plot RMSE\n",
    "results = clf.evals_result()\n",
    "train_mae, val_mae = results[\"validation_0\"][\"mae\"], results[\"validation_1\"][\"mae\"]\n",
    "x_values = range(0, len(train_mae))\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.plot(x_values, train_mae, label=\"Train MAE\")\n",
    "ax.plot(x_values, val_mae, label=\"Validation MAE\")\n",
    "ax.legend()\n",
    "plt.ylabel(\"MAE Loss\")\n",
    "plt.title(\"XGBoost MAE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4imhYDhQqCwD"
   },
   "outputs": [],
   "source": [
    "TOP = 20\n",
    "importance_data = pd.DataFrame({'name': clf.feature_names_in_, 'importance': clf.feature_importances_})\n",
    "importance_data = importance_data.sort_values(by='importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(data=importance_data[:TOP],\n",
    "            x = 'importance',\n",
    "            y = 'name'\n",
    "        )\n",
    "patches = ax.patches\n",
    "count = 0\n",
    "for patch in patches:\n",
    "    height = patch.get_height()\n",
    "    width = patch.get_width()\n",
    "    perc = 100*importance_data['importance'].iloc[count]#100*width/len(importance_data)\n",
    "    ax.text(width, patch.get_y() + height/2, f'{perc:.1f}%')\n",
    "    count+=1\n",
    "\n",
    "plt.title(f'The top {TOP} features sorted by importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VoyKzAcrfG7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
