{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed417750",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbed1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import  matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import holidays\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1ea69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "gas_df = pd.read_csv(\"gas_prices.csv\")\n",
    "electricity_df = pd.read_csv(\"electricity_prices.csv\")\n",
    "client_df = pd.read_csv(\"client.csv\")\n",
    "fw_df = pd.read_csv(\"forecast_weather.csv\")\n",
    "hw_df = pd.read_csv(\"historical_weather.csv\")\n",
    "location = pd.read_csv(\"county_lon_lats.csv\")\n",
    "location = location.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81efc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureProcessorClass():\n",
    "    def __init__(self):\n",
    "        # Columns to join on for the different datasets\n",
    "        self.weather_join = ['datetime', 'county', 'data_block_id']\n",
    "        self.gas_join = ['datetime','data_block_id']\n",
    "        self.electricity_join = ['datetime', 'data_block_id']\n",
    "        self.client_join = ['county', 'is_business', 'product_type', 'data_block_id']\n",
    "        self.holiday = ['datetime']\n",
    "        # Columns of latitude & longitude\n",
    "        self.lat_lon_columns = ['latitude', 'longitude']\n",
    "\n",
    "        # Aggregate stats\n",
    "        self.agg_stats = ['mean'] #, 'min', 'max', 'std', 'median']\n",
    "\n",
    "        # Categorical columns (specify for XGBoost)\n",
    "        self.category_columns = ['county', 'is_business', 'product_type', 'is_consumption', 'data_block_id','holiday']\n",
    "\n",
    "    def create_new_column_names(self, df, suffix, columns_no_change):\n",
    "        '''Change column names by given suffix, keep columns_no_change, and return back the data'''\n",
    "        df.columns = [col + suffix\n",
    "                      if col not in columns_no_change\n",
    "                      else col\n",
    "                      for col in df.columns\n",
    "                      ]\n",
    "        return df\n",
    "\n",
    "    def flatten_multi_index_columns(self, df):\n",
    "        df.columns = ['_'.join([col for col in multi_col if len(col)>0])\n",
    "                      for multi_col in df.columns]\n",
    "        return df\n",
    "\n",
    "    def create_data_features(self, data):\n",
    "        '''ğŸ“ŠCreate features for main data (test or train) setğŸ“Š'''\n",
    "        # To datetime\n",
    "        data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "        # Time period features\n",
    "        data['date'] = data['datetime'].dt.normalize()\n",
    "        data['year'] = data['datetime'].dt.year\n",
    "        data['quarter'] = data['datetime'].dt.quarter\n",
    "        data['month'] = data['datetime'].dt.month\n",
    "        data['week'] = data['datetime'].dt.isocalendar().week\n",
    "        data['hour'] = data['datetime'].dt.hour\n",
    "\n",
    "        # Day features\n",
    "        data['day_of_year'] = data['datetime'].dt.day_of_year\n",
    "        data['day_of_month']  = data['datetime'].dt.day\n",
    "        data['day_of_week'] = data['datetime'].dt.day_of_week\n",
    "        return data\n",
    "\n",
    "    def create_client_features(self, client):\n",
    "        '''ğŸ’¼ Create client features ğŸ’¼'''\n",
    "        # Modify column names - specify suffix\n",
    "        client = self.create_new_column_names(client,\n",
    "                                           suffix='_client',\n",
    "                                           columns_no_change = self.client_join\n",
    "                                          )\n",
    "        client['data_block_id']-=2\n",
    "        return client\n",
    "\n",
    "    def create_historical_weather_features(self, historical_weather):\n",
    "        '''âŒ›ğŸŒ¤ï¸ Create historical weather features ğŸŒ¤ï¸âŒ›'''\n",
    "\n",
    "        # To datetime\n",
    "        historical_weather['datetime'] = pd.to_datetime(historical_weather['datetime'])\n",
    "\n",
    "        # Add county\n",
    "        historical_weather[self.lat_lon_columns] = historical_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        historical_weather = historical_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        historical_weather = self.create_new_column_names(historical_weather,\n",
    "                                                          suffix='_h',\n",
    "                                                          columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                          )\n",
    "\n",
    "        # Group by & calculate aggregate stats\n",
    "        agg_columns = [col for col in historical_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        historical_weather = historical_weather.groupby(self.weather_join).agg(agg_dict).reset_index()\n",
    "        # Flatten the multi column aggregates\n",
    "        historical_weather = self.flatten_multi_index_columns(historical_weather)\n",
    "\n",
    "        # Test set has 1 day offset for hour<11 and 2 day offset for hour>11\n",
    "        # historical_weather['hour_h'] = historical_weather['datetime'].dt.hour\n",
    "        # historical_weather['datetime'] = (historical_weather\n",
    "        #                                        .apply(lambda x:\n",
    "        #                                               x['datetime'] + pd.DateOffset(1)\n",
    "        #                                               if x['hour_h']< 11\n",
    "        #                                               else x['datetime'] + pd.DateOffset(2),\n",
    "        #                                               axis=1)\n",
    "        #                                       )\n",
    "        historical_weather['data_block_id'] = historical_weather['data_block_id'].astype(int)\n",
    "        historical_weather['data_block_id'] -= 1\n",
    "\n",
    "        return historical_weather\n",
    "\n",
    "    def create_forecast_weather_features(self, forecast_weather):\n",
    "        '''ğŸ”®ğŸŒ¤ï¸ Create forecast weather features ğŸŒ¤ï¸ğŸ”®'''\n",
    "\n",
    "        # Rename column and drop\n",
    "        forecast_weather = (forecast_weather\n",
    "                            .rename(columns = {'forecast_datetime': 'datetime'})\n",
    "                            .drop(columns = 'origin_datetime')\n",
    "                           )\n",
    "\n",
    "        # To datetime\n",
    "        forecast_weather['datetime'] = (pd.to_datetime(forecast_weather['datetime'])\n",
    "                                        .dt\n",
    "                                        .tz_localize(None)\n",
    "                                       )\n",
    "\n",
    "        # Add county\n",
    "        forecast_weather[self.lat_lon_columns] = forecast_weather[self.lat_lon_columns].astype(float).round(1)\n",
    "        forecast_weather = forecast_weather.merge(location, how = 'left', on = self.lat_lon_columns)\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        forecast_weather = self.create_new_column_names(forecast_weather,\n",
    "                                                        suffix='_f',\n",
    "                                                        columns_no_change = self.lat_lon_columns + self.weather_join\n",
    "                                                        )\n",
    "\n",
    "        # Group by & calculate aggregate stats\n",
    "        agg_columns = [col for col in forecast_weather.columns if col not in self.lat_lon_columns + self.weather_join]\n",
    "        agg_dict = {agg_col: self.agg_stats for agg_col in agg_columns}\n",
    "        forecast_weather = forecast_weather.groupby(self.weather_join).agg(agg_dict).reset_index()\n",
    "\n",
    "        # Flatten the multi column aggregates\n",
    "        forecast_weather = self.flatten_multi_index_columns(forecast_weather)\n",
    "        forecast_weather['data_block_id'] -= 1\n",
    "        return forecast_weather\n",
    "\n",
    "    def create_electricity_features(self, electricity):\n",
    "        '''âš¡ Create electricity prices features âš¡'''\n",
    "        # To datetime\n",
    "        electricity['forecast_date'] = pd.to_datetime(electricity['forecast_date'])\n",
    "\n",
    "        # Test set has 1 day offset\n",
    "        electricity['datetime'] = electricity['forecast_date']\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        electricity = self.create_new_column_names(electricity,\n",
    "                                                   suffix='_electricity',\n",
    "                                                   columns_no_change = self.electricity_join)\n",
    "        electricity['data_block_id']-=1\n",
    "        return electricity\n",
    "\n",
    "    def create_gas_features(self, gas):\n",
    "        '''â›½ Create gas prices features â›½'''\n",
    "        gas['forecast_date'] = pd.to_datetime(gas['forecast_date'])\n",
    "        gas['datetime'] = gas['forecast_date']\n",
    "\n",
    "        # Mean gas price\n",
    "        gas['mean_price_per_mwh'] = (gas['lowest_price_per_mwh'] + gas['highest_price_per_mwh'])/2\n",
    "\n",
    "        # Modify column names - specify suffix\n",
    "        gas = self.create_new_column_names(gas,\n",
    "                                           suffix='_gas',\n",
    "                                           columns_no_change = self.gas_join\n",
    "                                          )\n",
    "        gas['data_block_id']-=1\n",
    "\n",
    "        return gas\n",
    "\n",
    "    def get_holiday_features(self, df, country_code='US'):\n",
    "\n",
    "        year_range = list(range(min(df['datetime'].dt.year), max(df['datetime'].dt.year) + 1))\n",
    "        country_holidays = holidays.country_holidays(\n",
    "        country_code,\n",
    "        years=year_range,\n",
    "        observed=False\n",
    "        )\n",
    "        holiday = pd.DataFrame(country_holidays.items())\n",
    "        holiday.columns = ['date', 'holiday']\n",
    "        holiday['date'] = pd.to_datetime(holiday['date'])\n",
    "        holiday = holiday.rename(columns={'date': 'datetime'})\n",
    "        holiday['datetime'] = pd.to_datetime(holiday['datetime'])\n",
    "\n",
    "        return holiday\n",
    "    def __call__(self, data, client, historical_weather, forecast_weather, electricity, gas):\n",
    "        '''Processing of features from all datasets, merge together and return features for dataframe df '''\n",
    "        # Create features for relevant dataset\n",
    "        data = self.create_data_features(data)\n",
    "        client = self.create_client_features(client)\n",
    "        historical_weather = self.create_historical_weather_features(historical_weather)\n",
    "        forecast_weather = self.create_forecast_weather_features(forecast_weather)\n",
    "        electricity = self.create_electricity_features(electricity)\n",
    "        gas = self.create_gas_features(gas)\n",
    "        holiday = self.get_holiday_features(data)\n",
    "        # ğŸ”— Merge all datasets into one df ğŸ”—\n",
    "        df = data.merge(client, how='left', on = self.client_join)\n",
    "        df = df.merge(historical_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(forecast_weather, how='left', on = self.weather_join)\n",
    "        df = df.merge(electricity, how='left', on = self.electricity_join)\n",
    "        df = df.merge(gas, how='left', on = self.gas_join)\n",
    "        df = df.merge(holiday, how='left', on = self.holiday)\n",
    "        # Assuming 'df' is your DataFrame containing the 'holiday' column\n",
    "        df['holiday'] = df['holiday'].fillna(0)  # Fill NaN values with 0\n",
    "        df.loc[df['holiday'] != 0, 'holiday'] = 1  # Change non-zero values to 1\n",
    "\n",
    "\n",
    "        # Change columns to categorical for XGBoost\n",
    "        df[self.category_columns] = df[self.category_columns].astype('category')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_revealed_targets_train(data, N_day_lags):\n",
    "    '''ğŸ¯ Create past revealed_targets for train set based on number of day lags N_day_lags ğŸ¯ '''\n",
    "    original_datetime = data['datetime']\n",
    "    revealed_targets = data[['datetime', 'prediction_unit_id', 'is_consumption', 'target']].copy()\n",
    "\n",
    "    # Create revealed targets for all day lags\n",
    "    for day_lag in range(2, N_day_lags+1):\n",
    "        revealed_targets['datetime'] = original_datetime + pd.DateOffset(day_lag)\n",
    "        data = data.merge(revealed_targets,\n",
    "                          how='left',\n",
    "                          on = ['datetime', 'prediction_unit_id', 'is_consumption'],\n",
    "                          suffixes = ('', f'_{day_lag}_days_ago')\n",
    "                         )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create all features\n",
    "\n",
    "FeatureProcessor = FeatureProcessorClass()\n",
    "\n",
    "data = FeatureProcessor(data = train_df.copy(),\n",
    "                      client = client_df.copy(),\n",
    "                      historical_weather = hw_df.copy(),\n",
    "                      forecast_weather = fw_df.copy(),\n",
    "                      electricity = electricity_df.copy(),\n",
    "                      gas = gas_df.copy(),\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc23196",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_day_lags = 7 # Specify how many days we want to go back (at least 2)\n",
    "\n",
    "df = create_revealed_targets_train(data.copy(),\n",
    "                                  N_day_lags = N_day_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b00288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty target row\n",
    "target = 'target'\n",
    "df = df[df[target].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create single fold split ######\n",
    "train_block_id = list(range(0, 600))\n",
    "\n",
    "tr = df[df['data_block_id'].isin(train_block_id)] # first 600 data_block_ids used for training\n",
    "val = df[~df['data_block_id'].isin(train_block_id)] # rest data_block_ids used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns for features\n",
    "no_features = ['date',\n",
    "                'latitude',\n",
    "                'longitude',\n",
    "                'data_block_id',\n",
    "                'row_id',\n",
    "                'hours_ahead',\n",
    "                'hour_h',\n",
    "               ]\n",
    "\n",
    "remove_columns = [col for col in df.columns for no_feature in no_features if no_feature in col]\n",
    "remove_columns.append(target)\n",
    "features = [col for col in df.columns if col not in remove_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe013f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = np.array(tr[features])\n",
    "val_features = np.array(val[features])\n",
    "\n",
    "# reshape features for LSTM: [samples, timesteps, features]\n",
    "tr_features = np.array(tr_features).reshape((tr_features.shape[0], 1, tr_features.shape[1]))\n",
    "val_features = np.array(val_features).reshape((val_features.shape[0], 1, val_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6623c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(1024,\n",
    "                              return_sequences=True,\n",
    "                              activation='relu',\n",
    "                              input_shape=(tr_features.shape[1], tr_features.shape[2]))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=True, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss=MeanAbsoluteError(), metrics=['acc'])  # Example optimizer, loss, and metrics\n",
    "model.build(input_shape=(None, tr_features.shape[1], tr_features.shape[2]))\n",
    "\n",
    "# Now you can access the summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ce7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,          # verbose mode will print out extra information\n",
    "    mode='min',         # the training will stop when the quantity monitored has stopped decreasing\n",
    "    patience=5          # number of epochs with no improvement after which training will be stopped\n",
    ")\n",
    "\n",
    "# fit the LSTM model to the training data\n",
    "history = model.fit(\n",
    "    tr_features, tr[target],                       # training data and labels\n",
    "    epochs=15,                             # maximum number of epochs to run\n",
    "    batch_size=1024,                        # batch size for training\n",
    "    validation_data=(val_features, val[target]),       # validation data for evaluating the model\n",
    "    callbacks=[earlyStop],                  # list of callbacks, in this case just EarlyStopping\n",
    "    verbose=1,                              # verbose mode will print out extra information per epoch\n",
    "    shuffle=False                           # don't shuffle the data, usually important in time series\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d383f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54caa5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
